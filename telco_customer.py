# -*- coding: utf-8 -*-
"""telco_customer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15BNBQETPgh8K8Kjfj0EiEwHwjLdaG7RO
"""



#import spark machine learning modules
from pyspark.sql import SparkSession
from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier
from pyspark.ml.feature import VectorAssembler, StringIndexer, Normalizer
from pyspark.sql.functions import isnan, col, when, count
from pyspark.ml.evaluation import MulticlassClassificationEvaluator

#create a spark session

spark = SparkSession.builder.appName("telcom_customer").getOrCreate()

#read csv file into spark dataframe
telco_data = spark.read.csv("/home/fundi/moringaschool/week10/machinelearning/telecom_dataset.csv", header=True)
telco_data.show()
telco_data.dtypes

#data cleaning
#check for missing values
telco_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in telco_data.columns]).show()

#convert string columns to float
int_columns = ['CustomerID', 'Age', 'MonthlyCharges', 'TotalCharges']
for c in int_columns:
  telco_data = telco_data.withColumn(c, col(c).cast("integer"))

#feature encoding
stringindexer = StringIndexer(inputCols=["Gender", "Contract", 'Churn'], outputCols=["gender_idx", "contract_idx", "churn_idx"])
model_si = stringindexer.fit(telco_data)
telco_data_indexed = model_si.transform(telco_data).drop("Gender").drop("Contract").drop("Churn")

#feature columns and target column
features_columns = [c for c in telco_data_indexed.columns if c != "Churn"]
label_col = "churn_idx"

#vectorize the feature colummns
assembler = VectorAssembler(inputCols= features_columns, outputCol= "features" )
telco_data_assembled = assembler.transform(telco_data_indexed)
telco_data_assembled.show()
print(telco_data_assembled.dtypes)

#feature scaling
normalizer = Normalizer(inputCol="features", outputCol="normalized_features")
telco_data_normalized = normalizer.transform(telco_data_assembled)
telco_data_normalized.show()

#split data into train and test data
splits = telco_data_normalized.randomSplit([0.7, 0.3])
train_data = splits[0]
test_data = splits[1]
test_data.show()

#create the classification model, logistic algorithm
lr = LogisticRegression(featuresCol="normalized_features", labelCol= label_col, )

#train the model
lr_model = lr.fit(train_data)

#test the model using the test data
predictions_lr = lr_model.transform(test_data)
predictions_lr.show()

#decisiontree classification algorithm
dt = DecisionTreeClassifier(featuresCol="normalized_features", labelCol=label_col, maxDepth=3)
#create the model
dt_model = dt.fit(train_data)

#test the model using test data
predictions_dt = dt_model.transform(test_data)
predictions_dt.show()

#evaluating classification model 
evaluator = MulticlassClassificationEvaluator(labelCol=label_col)


#evaluation metrics for logistic model
accuracy_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName:"accuracy"})
precision_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName:"weightedPrecision"})
recall_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName:"weightedRecall"})
f1_lr = evaluator.evaluate(predictions_lr, {evaluator.metricName:"f1"})

#evaluation metrics for decisiontree model
accuracy_dt = evaluator.evaluate(predictions_dt, {evaluator.metricName:"accuracy"})
precision_dt = evaluator.evaluate(predictions_dt, {evaluator.metricName:"weightedPrecision"})
recall_dt = evaluator.evaluate(predictions_dt, {evaluator.metricName:"weightedRecall"})
f1_dt = evaluator.evaluate(predictions_dt, {evaluator.metricName:"f1"})

print(f"""
    evaluation metric for the logistic model
    accuracy:{accuracy_lr},  precision:{precision_lr}, recall:{recall_lr}, fi_score:{f1_lr}
      """)
print(f"""
    evaluation metric for the decisiontree model
    accuracy:{accuracy_dt},  precision:{precision_dt}, recall:{recall_dt}, fi_score:{f1_dt}
      """)

